{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Recommender System project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful libraries to import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj2_helpers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_ID(string):\n",
    "    \"\"\"Convert the string ID of the form 'r44_c1' into the user_id 44 and movie_id 1\"\"\"\n",
    "    remove_chars = string.replace(\"r\",\"\").replace(\"c\", \"\").replace(\"_\", \" \")\n",
    "    split = remove_chars.split()\n",
    "    user_id = int(split[0])\n",
    "    movie_id = int(split[1])\n",
    "    return user_id, movie_id\n",
    "\n",
    "def load_csv_data(data_path, nb_users, nb_movies):\n",
    "    \"\"\"Loads data and returns the rating matrix\"\"\"\n",
    "    X = np.genfromtxt(data_path, dtype= str, delimiter=',', skip_header = True)\n",
    "    ratings_matrix = np.zeros((nb_users, nb_movies), dtype=np.int)\n",
    "    ids = np.zeros((len(X), 2), dtype=np.int)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        user_id, movie_id = convert_ID(X[i][0])\n",
    "        ids[i] = [user_id, movie_id]\n",
    "        ### Check for errors\n",
    "        if(user_id > 0 and user_id <= nb_users and movie_id > 0 and movie_id <= nb_movies):\n",
    "            ### Use -1 because IDs start at 1 and we want them to start at 0\n",
    "            ratings_matrix[user_id - 1][movie_id - 1] = int(X[i][1])\n",
    "        else:\n",
    "            print(\"Error with user {} and movie {}\".format(user_id, movie_id))\n",
    "    return ratings_matrix, ids\n",
    "\n",
    "def movie_user_predictions(sample_matrix):\n",
    "    \"\"\"Compute the matrix of indices we want to predict with movies as rows and users \n",
    "    for which we want to predict the rating for this movie\"\"\"\n",
    "    result = []\n",
    "    movie_user_matrix = sample_matrix.T\n",
    "    for movie_ratings in movie_user_matrix:\n",
    "        user_indices = [user for user, rating in enumerate(movie_ratings) if rating != 0]\n",
    "        result.append(user_indices)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. We also need the sample ids as those are the ratings that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loading sample\n"
     ]
    }
   ],
   "source": [
    "nb_users = 10000\n",
    "nb_movies = 1000\n",
    "print(\"Loading data\")\n",
    "ratings_matrix, ids = load_csv_data(\"data_train.csv\", nb_users, nb_movies)\n",
    "print(\"Loading sample\")\n",
    "sample_matrix, sample_ids = load_csv_data(\"sample_submission.csv\", nb_users, nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_to_predict = movie_user_predictions(sample_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 72, 155, 159, 247]\n",
      "[[ 37   1]\n",
      " [ 73   1]\n",
      " [156   1]\n",
      " [160   1]\n",
      " [248   1]]\n"
     ]
    }
   ],
   "source": [
    "print(ratings_to_predict[0][:5])\n",
    "print(sample_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the ratings: 3.8572805008190647\n",
      "Sparsity of the matrix: 88.23048%\n",
      "The median of ratings amount per user is 104.0\n",
      "Minimum ratings: 3, Maximum ratings: 522\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(ratings_matrix[ratings_matrix != 0])\n",
    "print(\"Mean of the ratings: {}\".format(mean))\n",
    "sparsity = 100 * (1 - (len(ratings_matrix[ratings_matrix != 0]) / (nb_users * nb_movies)))\n",
    "print(\"Sparsity of the matrix: {}%\".format(sparsity))\n",
    "ratings_per_user = np.count_nonzero(ratings_matrix, axis = 1)\n",
    "ratings_per_movie = np.count_nonzero(ratings_matrix, axis = 0)\n",
    "print(\"The median of ratings amount per user is {}\".format(np.median(ratings_per_user)))\n",
    "print(\"The median of ratings amount per movie is {}\".format(np.median(ratings_per_movie)))\n",
    "print(\"Minimum ratings: {}, Maximum ratings: {}\".format(min(ratings_per_user), max(ratings_per_user)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the value of ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP61y/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdb6573bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43508  99180 274327 324700 435237]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "distrib_ratings, bins_ratings = np.histogram(ratings_matrix[ratings_matrix != 0], bins = [1, 2, 3, 4, 5, 6])\n",
    "percentages_ratings = 100 * distrib_ratings / np.sum(distrib_ratings)\n",
    "\n",
    "plt.bar(bins_ratings[:-1], percentages_ratings, width = 0.3, color = 'orange')\n",
    "plt.xlabel(\"Ratings\")\n",
    "plt.ylabel(\"Rating distribution in %\")\n",
    "plt.show()\n",
    "\n",
    "print(distrib_ratings)\n",
    "print(bins_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of number of ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8pAkdWbykCR19v8BWOaK5d1VziUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdb612a3278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Compute number of movies seen by each user\n",
    "movies_rated = np.count_nonzero(ratings_matrix, axis = 1)\n",
    "\n",
    "distrib_movies, bins_movies = np.histogram(movies_rated, bins = range(0,550,25))\n",
    "plt.bar(bins_movies[:-1], distrib_movies, width = 20, color = 'green', align = 'edge')\n",
    "plt.xlabel(\"Number of ratings\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommender system designed through this project uses the User-User Collaborative Filtering method. Collaborative filtering (CF) is a popular recommendation algorithm that bases the predictions and recommendations on the past ratings of users in the system. Thus, User-user CF consists of finding other users whose past rating behavior is similar to the one of the current user and uses their ratings on other items to predict what the current user will like.\n",
    "\n",
    "To compute the predictions for each user in the algorithm, we need a similarity function $s(u, v)$ computing the similarity between two users: u and v. The similarity function is used to compute a neighborhood $\\mathbf{K} \\subseteq U$ for each user u that consists of the K users that are most similar to u. Finally, the predicted rating for user u and movie i will be computed using the set of neighbors $\\mathbf{K}$ , as follows:\n",
    "    \n",
    "$$p_{u, i} = \\frac{\\sum_{v \\in \\mathbf{K}} s(u, v) . r_{v,i}}{\\sum_{v \\in \\mathbf{K}} |s(u, v)|}$$\n",
    "    \n",
    "where ${r}_{v,i}$ is the rating user v gave to movie i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Similarity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a similarity function to compute all similarities between users or movies, we will try the following functions:\n",
    "    - cosine similarity\n",
    "    - euclidean distance\n",
    "    - pearson correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users are represented as $I$-dimensional vectors and the similarity is computed by taking their dot product divided by the product of their Euclidean norms:\n",
    "    \n",
    "$$s(u,v) = \\frac{\\mathbf{r}_{u}.\\mathbf{r}_{v}}{\\lVert \\mathbf{r}_{u} \\rVert_{2} \\lVert \\mathbf{r}_{v} \\rVert_{2}} = \\frac{\\sum_{i} r_{u,i}.r_{v,i}}{\\sqrt{\\sum_{i} r_{u,i}^2} \\sqrt{\\sum_{i} r_{v,i}^2}} $$\n",
    "    \n",
    "where $\\mathbf{r}_{u}$ and $\\mathbf{r}_{v}$ are the rating vectors of user $u$ and $v$ respectively. Unknown ratings are considered to be $0.0$ and this causes them to drop out of the numerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.09836635,  0.20147319, ...,  0.05138538,\n",
       "         0.19649248,  0.17267498],\n",
       "       [ 0.09836635,  0.        ,  0.12758677, ...,  0.05600622,\n",
       "         0.22168764,  0.24500193],\n",
       "       [ 0.20147319,  0.12758677,  0.        , ...,  0.10204437,\n",
       "         0.23786563,  0.20604448],\n",
       "       ..., \n",
       "       [ 0.05138538,  0.05600622,  0.10204437, ...,  0.        ,\n",
       "         0.14194186,  0.21796069],\n",
       "       [ 0.19649248,  0.22168764,  0.23786563, ...,  0.14194186,\n",
       "         0.        ,  0.18952854],\n",
       "       [ 0.17267498,  0.24500193,  0.20604448, ...,  0.21796069,\n",
       "         0.18952854,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "### similarity = 1 - distance\n",
    "cosine_matrix = np.ones((nb_users, nb_users)) - sk.metrics.pairwise_distances(ratings_matrix, metric='cosine')\n",
    "### Set to 0 the similarity from user to itself\n",
    "cosine_matrix -= np.identity(nb_users)\n",
    "cosine_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopKNeighbors(similarities, K):\n",
    "    \"\"\"Given the similarities of a user as an array, only keep the K best (max) similarities\n",
    "       by setting other similarities to 0\"\"\"\n",
    "    copy = np.copy(similarities)\n",
    "    index = len(similarities) - K\n",
    "    # Get the similarity value of the K best neighbor\n",
    "    bestNeighborsVal = np.partition(similarities, index)[index]\n",
    "    low_values_indices = copy < bestNeighborsVal # Where values are below the threshold\n",
    "    copy[low_values_indices] = 0.0\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = getTopKNeighbors(cosine_matrix[1], 100)\n",
    "len(test[test != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Predict the ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods uses a different neighborhood for each user and item: the neighbors must have seen the movie that we want to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute all predictions user per user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Too long for computation as it computes all predictions: 10 millions\"\"\"\n",
    "### similarities is the array of similarities for the considered user\n",
    "### ratings is the transpose ratings_matrix (movies x users)\n",
    "### K_best is the number of best neighbors (integer)\n",
    "def compute_predictions(ratings_movie_user, similarities, K_best):\n",
    "    \"\"\"Compute all the predictions for a particular user\"\"\"\n",
    "    # Create matrix with same columns of similarities with length of ratings_movie_user as the number of columns\n",
    "    copiedSimilarities = np.tile(similarities, (len(ratings_movie_user), 1)).T\n",
    "    # Set similarities to 0.0 when the other users haven't rated the movie (don't take them in consideration for calculus)\n",
    "    copiedRatings = np.copy(ratings_movie_user) #This copy is really really important !!!\n",
    "    copiedRatings[copiedRatings != 0.0] = 1.0\n",
    "    copiedSimilarities = np.multiply(copiedSimilarities, ratings_movie_user.T)\n",
    "    \n",
    "    # Apply function getTopNNeighbors to each column of copiedSimilarities\n",
    "    bestNeighbors = np.apply_along_axis(getTopKNeighbors, 0, copiedSimilarities, K_best)\n",
    "    # Get a list of sums of each column of copiedSimilarities\n",
    "    sumSimilarities = np.sum(bestNeighbors, axis = 0)\n",
    "\n",
    "    #Compute prediction: dot product of the items in partialRatings @ similarities of K best neighbors -> just get diagonal values\n",
    "    predictions = np.einsum('ij,ji->i', ratings_movie_user, bestNeighbors)\n",
    "    predictions = predictions / sumSimilarities\n",
    "    predictions[np.isnan(predictions)] = 0.0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Too long for computation as it computes all predictions: 10 millions\"\"\"\n",
    "def compute_matrix(ratings_matrix, similarity_matrix, K_best):\n",
    "    \"\"\"Compute the matrix of predictions by running the compute_predictions for each user\"\"\"\n",
    "    nb_users = len(ratings_matrix)\n",
    "    nb_movies = len(ratings_matrix[0])\n",
    "    predictions_matrix = np.zeros((nb_users, nb_movies))\n",
    "    for user in range(nb_users):\n",
    "        if(user%100 == 0):\n",
    "            print(user)\n",
    "        similarities_user = similarity_matrix[user]\n",
    "        predictions_user = compute_predictions(np.copy(ratings_matrix).T, similarities_user, K_best)\n",
    "        predictions_matrix[user] = predictions_user\n",
    "    return predictions_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.54324212,  4.60861297,  4.88102289,  5.        ,  4.95293621,\n",
       "        5.        ,  4.95393599,  5.        ,  4.4613122 ,  5.        ,\n",
       "        4.96149018,  4.61802447,  4.64064601,  5.        ,  4.97987434,\n",
       "        4.88740051,  4.84013087,  4.15409638,  4.85258086,  4.906893  ,\n",
       "        5.        ,  4.93330472,  4.77831891,  4.87040958,  4.8112198 ,\n",
       "        5.        ,  4.82330761,  4.76100714,  4.95304526,  4.990789  ,\n",
       "        4.34527446,  4.99049836,  5.        ,  4.86102955,  4.79809704,\n",
       "        4.20434277,  5.        ,  4.48687281,  3.93977225,  4.98159892,\n",
       "        3.07013611,  4.98136038,  4.89873734,  5.        ,  5.        ,\n",
       "        5.        ,  4.25567443,  4.99081252,  3.76293544,  4.60142872,\n",
       "        5.        ,  4.3555217 ,  4.97183566,  4.32872013,  4.99067058,\n",
       "        3.39743368,  4.91811147,  3.5162759 ,  5.        ,  5.        ,\n",
       "        5.        ,  4.60296054,  4.96268449,  4.76663116,  4.7380959 ,\n",
       "        4.81395211,  4.46278671,  4.99052687,  5.        ,  4.50178644,\n",
       "        4.99054508,  5.        ,  3.86514836,  4.71659124,  3.88351198,\n",
       "        5.        ,  5.        ,  4.94225519,  4.93650002,  4.54470544,\n",
       "        4.61104369,  4.66557959,  4.5912784 ,  5.        ,  4.86167152,\n",
       "        5.        ,  4.90933059,  4.99077885,  5.        ,  4.9154735 ,\n",
       "        4.91790577,  5.        ,  5.        ,  4.99031298,  5.        ,\n",
       "        4.49413463,  4.35461096,  4.68515844,  5.        ,  4.87092064,\n",
       "        4.99065476,  5.        ,  4.95521839,  4.17058964,  4.97238759,\n",
       "        4.98985232,  4.79284869,  4.57196672,  4.49484628,  4.53665633,\n",
       "        4.57291806,  4.98113639,  4.88009903,  4.55323338,  3.90935051,\n",
       "        4.82888883,  5.        ,  5.        ,  4.13612564,  4.92563646,\n",
       "        4.74098521,  4.94320607,  4.55775582,  4.99055231,  4.85690758,\n",
       "        4.99064728,  4.96274119,  4.35086195,  3.96658188,  4.50436101,\n",
       "        5.        ,  4.84199495,  4.57344745,  5.        ,  4.65053329,\n",
       "        4.72490678,  4.29450917,  4.98180538,  4.99032362,  4.50324981,\n",
       "        4.93423396,  4.4875398 ,  5.        ,  4.80388606,  4.49303458,\n",
       "        4.98138273,  3.37521678,  5.        ,  4.41874228,  4.48821288,\n",
       "        3.78537941,  4.49427456,  3.87118104,  4.63231208,  4.97245585,\n",
       "        5.        ,  4.90586267,  4.71544342,  4.99080061,  4.99073145,\n",
       "        5.        ,  4.70015374,  4.95371467,  4.8986762 ,  4.97190464,\n",
       "        3.64453623,  4.46045728,  4.94394869,  5.        ,  4.99001309,\n",
       "        5.        ,  4.67902425,  5.        ,  4.98134747,  4.29485223,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  4.80486109,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  3.86329177,\n",
       "        5.        ,  4.71977368,  5.        ,  4.81036643,  4.51401676,\n",
       "        5.        ,  4.47070695,  5.        ,  4.28457702,  3.75827719,\n",
       "        4.9639272 ,  5.        ,  5.        ,  4.86221543,  5.        ,\n",
       "        4.17354133,  4.77032178,  5.        ,  4.21406284,  4.63916895,\n",
       "        5.        ,  4.70052726,  5.        ,  3.60753555,  4.8975343 ,\n",
       "        4.9810755 ,  4.7918022 ,  5.        ,  5.        ,  4.98944855,\n",
       "        5.        ,  4.90752189,  4.8396062 ,  4.94331679,  4.95397134,\n",
       "        4.58651357,  4.77349395,  4.87030145,  4.97175264,  4.75567469,\n",
       "        4.70183732,  5.        ,  4.95317556,  4.26630819,  5.        ,\n",
       "        4.44434447,  4.53484554,  4.88571746,  4.98156955,  5.        ,\n",
       "        4.98127642,  5.        ,  4.79944098,  4.74176465,  5.        ,\n",
       "        4.99068671,  4.99005402,  3.43358458,  4.87101147,  5.        ,\n",
       "        5.        ,  5.        ,  4.7605458 ,  5.        ,  5.        ,\n",
       "        5.        ,  4.55076102,  4.97158993,  4.8917814 ,  3.42782699,\n",
       "        5.        ,  5.        ,  4.98997827,  4.99044378,  4.86744067,\n",
       "        4.30321381,  5.        ,  4.50641393,  4.99043911,  4.49892362,\n",
       "        5.        ,  4.62032404,  4.58797288,  4.88873165,  4.70864902,\n",
       "        5.        ,  4.70218403,  4.31856695,  4.85387684,  4.28760606,\n",
       "        4.3999217 ,  4.49392344,  4.74382682,  4.32557258,  4.15792374,\n",
       "        4.17657859,  4.26028513,  5.        ,  4.9352511 ,  5.        ,\n",
       "        4.26865678,  4.89664018,  4.69306061,  4.9907125 ,  4.55626575,\n",
       "        4.99064571,  3.72982199,  4.5614976 ,  4.58791949,  5.        ,\n",
       "        5.        ,  4.98977507,  5.        ,  4.65665458,  5.        ,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  4.9714878 ,\n",
       "        4.98985076,  4.97943577,  5.        ,  5.        ,  5.        ,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  4.69883805,\n",
       "        4.97002747,  5.        ,  5.        ,  4.87028631,  5.        ,\n",
       "        5.        ,  5.        ,  4.2915347 ,  5.        ,  4.59807442,\n",
       "        5.        ,  4.60629319,  5.        ,  4.9232531 ,  4.94480571,\n",
       "        5.        ,  5.        ,  5.        ,  4.96246811,  4.96107722,\n",
       "        4.86273517,  5.        ,  5.        ,  4.43046052,  5.        ,\n",
       "        4.72714717,  5.        ,  4.89849664,  4.86360965,  4.97041011,\n",
       "        4.74531742,  4.80327596,  4.98100837,  5.        ,  5.        ,\n",
       "        5.        ,  4.9798151 ,  5.        ,  4.66555249,  3.64132615,\n",
       "        3.48448025,  4.16776304,  4.98129581,  4.64201831,  4.90034732,\n",
       "        4.79016802,  4.12098986,  4.95248147,  4.60646163,  4.85158747,\n",
       "        5.        ,  5.        ,  4.97166778,  5.        ,  5.        ,\n",
       "        4.51055859,  4.85153144,  4.5168279 ,  4.49097435,  4.78888203,\n",
       "        4.59380303,  4.5254824 ,  3.64414587,  5.        ,  4.98146523,\n",
       "        4.94361031,  4.33593529,  4.30281793,  4.91621985,  4.97179862,\n",
       "        4.96079613,  4.88730751,  4.72630069,  4.89549246,  3.79294674,\n",
       "        4.9627983 ,  4.99053459,  4.9418015 ,  4.73442538,  4.82683303,\n",
       "        5.        ,  4.97203544,  4.98093173,  5.        ,  4.48921443,\n",
       "        4.80464344,  5.        ,  5.        ,  4.46076844,  5.        ,\n",
       "        5.        ,  4.6681276 ,  4.72685929,  4.79852535,  4.98172924,\n",
       "        5.        ,  5.        ,  4.89883349,  4.31084095,  4.94435236,\n",
       "        5.        ,  5.        ,  5.        ,  4.66982294,  5.        ,\n",
       "        4.99053354,  4.58572197,  5.        ,  3.76818051,  5.        ,\n",
       "        5.        ,  5.        ,  4.93629809,  4.87962925,  4.99061091,\n",
       "        4.8882786 ,  4.96294928,  5.        ,  5.        ,  4.99069659,\n",
       "        4.28865551,  3.39566261,  3.99382444,  4.98137363,  5.        ,\n",
       "        4.1511098 ,  4.15489066,  4.38136102,  4.98126795,  5.        ,\n",
       "        4.99036634,  4.95378747,  4.85359695,  4.44819406,  4.89970409,\n",
       "        4.5465136 ,  4.93404801,  4.87212996,  4.84593004,  5.        ,\n",
       "        4.4568349 ,  5.        ,  5.        ,  5.        ,  3.62566996,\n",
       "        4.74525316,  4.68998739,  4.5546275 ,  5.        ,  4.97216314,\n",
       "        4.96225922,  4.82163548,  3.8079116 ,  4.73389487,  3.67321083,\n",
       "        5.        ,  4.98120854,  5.        ,  5.        ,  4.99061457,\n",
       "        4.9906424 ,  5.        ,  5.        ,  4.98115529,  4.95338883,\n",
       "        4.86343846,  5.        ,  4.85991244,  5.        ,  5.        ,\n",
       "        5.        ,  4.98993551,  5.        ,  5.        ,  4.99031072,\n",
       "        5.        ,  5.        ,  4.98082611,  5.        ,  5.        ,\n",
       "        4.98102364,  5.        ,  4.9905469 ,  4.98996017,  3.47371484,\n",
       "        5.        ,  5.        ,  3.95185821,  3.88758348,  3.1878766 ,\n",
       "        5.        ,  3.49923829,  5.        ,  4.77694317,  4.22885537,\n",
       "        4.93509011,  4.29948173,  3.52758437,  4.33669193,  4.23614054,\n",
       "        3.68170836,  4.94347744,  4.98049585,  3.96371794,  3.78333195,\n",
       "        4.04910476,  4.97955638,  4.98120798,  4.35091466,  5.        ,\n",
       "        4.17256426,  5.        ,  4.64017179,  4.96228671,  4.96263214,\n",
       "        4.22387442,  2.89933007,  4.89860987,  5.        ,  3.53756612,\n",
       "        5.        ,  4.40071179,  4.59757008,  4.34685034,  3.48327655,\n",
       "        4.20155448,  4.90033642,  4.78752134,  4.91573624,  5.        ,\n",
       "        5.        ,  4.99001875,  4.97178038,  4.91495272,  4.97156244,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  4.89710043,\n",
       "        4.99082169,  4.87873201,  4.93484883,  4.9815321 ,  4.73257239,\n",
       "        4.98102927,  4.97227225,  4.99023419,  4.58150057,  4.97199825,\n",
       "        4.01777269,  4.67936869,  4.27621453,  4.9906696 ,  5.        ,\n",
       "        4.99066558,  4.62063957,  5.        ,  4.7706445 ,  5.        ,\n",
       "        5.        ,  5.        ,  4.61240901,  4.52200688,  4.82708164,\n",
       "        4.989604  ,  4.73030068,  5.        ,  5.        ,  4.7542482 ,\n",
       "        5.        ,  4.99021576,  4.52431073,  4.66777869,  4.66654806,\n",
       "        5.        ,  4.63446076,  3.85135152,  5.        ,  5.        ,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  4.61186879,\n",
       "        5.        ,  5.        ,  3.78990322,  5.        ,  5.        ,\n",
       "        5.        ,  4.95318507,  5.        ,  4.98132711,  5.        ,\n",
       "        5.        ,  5.        ,  5.        ,  4.88004785,  5.        ,\n",
       "        5.        ,  5.        ,  4.99012194,  5.        ,  4.98995927,\n",
       "        4.99041543,  4.98112181,  5.        ,  4.94475123,  4.9904843 ,\n",
       "        5.        ,  3.87752159,  5.        ,  5.        ,  4.69845048,\n",
       "        5.        ,  5.        ,  5.        ,  4.46792243,  4.98120658,\n",
       "        4.96261935,  3.99724629,  5.        ,  4.93719177,  4.98988178,\n",
       "        4.99063589,  5.        ,  5.        ,  5.        ,  5.        ,\n",
       "        4.99032736,  5.        ,  5.        ,  4.99071562,  5.        ,\n",
       "        5.        ,  5.        ,  4.9343278 ,  5.        ,  4.99058455,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  5.        ,\n",
       "        5.        ,  5.        ,  5.        ,  5.        ,  4.98958833,\n",
       "        4.82403613,  5.        ,  5.        ,  5.        ,  5.        ,\n",
       "        4.8601717 ,  5.        ,  5.        ,  5.        ,  4.9525596 ,\n",
       "        4.9904302 ,  4.92651873,  4.90460171,  5.        ,  5.        ,\n",
       "        4.97982485,  5.        ,  5.        ,  5.        ,  5.        ,\n",
       "        5.        ,  4.93316088,  4.63664808,  5.        ,  5.        ,\n",
       "        5.        ,  3.77752918,  4.94459704,  5.        ,  4.99003037,\n",
       "        5.        ,  5.        ,  4.97086636,  5.        ,  5.        ,\n",
       "        4.95379338,  5.        ,  5.        ,  4.68108869,  5.        ,\n",
       "        5.        ,  4.90725831,  3.90268702,  4.01209279,  4.47562074,\n",
       "        3.4270299 ,  4.21397174,  4.3295632 ,  3.91543357,  4.21030975,\n",
       "        5.        ,  4.12393299,  4.99025574,  5.        ,  4.44108413,\n",
       "        3.60422224,  5.        ,  4.51636591,  4.62436738,  4.8292189 ,\n",
       "        4.86500116,  4.94554755,  4.61294669,  4.4804869 ,  3.96798873,\n",
       "        5.        ,  4.60069777,  4.99048197,  3.8658264 ,  4.04746933,\n",
       "        4.84567387,  5.        ,  4.98140385,  4.99086332,  4.88349648,\n",
       "        5.        ,  5.        ,  5.        ,  4.63800605,  5.        ,\n",
       "        5.        ,  4.99069041,  5.        ,  4.93587427,  4.83976395,\n",
       "        4.8615329 ,  4.96392028,  4.40248744,  5.        ,  5.        ,\n",
       "        5.        ,  4.40120155,  3.90011239,  4.95294801,  4.85801761,\n",
       "        4.49763068,  3.42675977,  4.386507  ,  4.79966794,  5.        ,\n",
       "        4.97194806,  4.8435911 ,  5.        ,  5.        ,  5.        ,\n",
       "        4.97155445,  5.        ,  5.        ,  5.        ,  5.        ,\n",
       "        4.990278  ,  5.        ,  5.        ,  5.        ,  4.04923183,\n",
       "        4.97165083,  4.33423248,  5.        ,  3.36054352,  4.99010888,\n",
       "        4.72239678,  5.        ,  4.32523751,  5.        ,  4.55639235,\n",
       "        5.        ,  5.        ,  4.66737765,  5.        ,  4.40029394,\n",
       "        4.98925937,  5.        ,  4.36407046,  5.        ,  4.56199409,\n",
       "        4.98145479,  5.        ,  5.        ,  4.69701828,  5.        ,\n",
       "        5.        ,  4.9810778 ,  5.        ,  5.        ,  4.99059765,\n",
       "        4.79616719,  4.6850712 ,  4.50105298,  4.98113717,  4.99043692,\n",
       "        5.        ,  4.81541795,  4.89016587,  4.84611649,  4.92552679,\n",
       "        3.67691021,  4.67554958,  5.        ,  4.91570139,  5.        ,\n",
       "        4.7629268 ,  5.        ,  4.87894376,  4.71266473,  4.30848293,\n",
       "        3.86934462,  4.84465933,  4.9725345 ,  4.83160502,  4.31129526,\n",
       "        5.        ,  3.91189773,  4.31402874,  4.94401926,  4.42296008,\n",
       "        4.96231177,  4.44350959,  4.98143151,  4.99085688,  4.27847306,\n",
       "        4.78362522,  5.        ,  4.8816188 ,  4.91733278,  5.        ,\n",
       "        4.64192255,  4.53189124,  4.96311604,  4.97181294,  4.95331435,\n",
       "        3.35940512,  4.67410378,  4.15938431,  4.4628303 ,  4.66722712,\n",
       "        4.05202906,  4.87893294,  4.80536843,  5.        ,  4.2917904 ,\n",
       "        4.48182609,  4.98963505,  4.01458206,  4.29041963,  4.86979027,\n",
       "        4.90580529,  4.18650275,  4.01444453,  5.        ,  3.97474639,\n",
       "        5.        ,  5.        ,  4.81663837,  4.16840146,  4.17540891,\n",
       "        4.53076478,  4.6312361 ,  5.        ,  4.05348319,  4.38780518,\n",
       "        4.81690927,  3.69629537,  4.92691493,  4.87173716,  4.91453598,\n",
       "        4.9906316 ,  4.59048304,  3.31490188,  4.80779153,  3.84102817,\n",
       "        4.84560391,  4.71400505,  5.        ,  4.58729089,  4.38772429,\n",
       "        3.8682115 ,  4.92686457,  3.19025682,  4.44386247,  4.21803196,\n",
       "        4.91497102,  3.5325072 ,  3.70471729,  3.82008931,  4.19718296,\n",
       "        4.98156115,  4.37499769,  4.90760454,  4.29569989,  5.        ,\n",
       "        4.9907205 ,  3.58900994,  4.13860015,  3.90280923,  4.20878538,\n",
       "        5.        ,  4.96236498,  3.73001072,  4.19659375,  5.        ,\n",
       "        3.61698734,  4.95356792,  2.82303447,  4.13802115,  4.26569374,\n",
       "        4.7530285 ,  4.74635753,  4.99079925,  4.44254773,  4.94284622,\n",
       "        4.77295458,  4.77492973,  4.43838131,  4.66281976,  4.82058914,\n",
       "        3.81134398,  5.        ,  4.62609955,  4.459887  ,  4.6430323 ,\n",
       "        3.23635005,  4.35161106,  3.72874944,  3.07062636,  5.        ,\n",
       "        4.38179286,  4.89520666,  3.79834475,  4.61942363,  3.0972103 ,\n",
       "        3.97343997,  3.60466503,  4.25413099,  3.00103033,  4.99095016,\n",
       "        3.64202089,  3.66762729,  3.76927702,  4.89567818,  3.23246814,\n",
       "        4.88962411,  5.        ,  3.72730033,  5.        ,  4.90865278,\n",
       "        4.99047737,  4.65640874,  4.66284919,  4.92760975,  4.59969483,\n",
       "        4.01046211,  4.16921818,  5.        ,  4.95337201,  4.97230161,\n",
       "        4.97136873,  5.        ,  4.95323321,  5.        ,  4.9717265 ,\n",
       "        5.        ,  4.97230736,  4.96240292,  4.97211654,  4.47015275,\n",
       "        4.52291464,  4.84443742,  4.34216439,  4.51219681,  5.        ,\n",
       "        4.98129935,  4.98127682,  4.57688398,  4.86304098,  5.        ])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This cell only for testing:\n",
    "preds_test = compute_predictions(np.copy(ratings_matrix).T, cosine_matrix[36], 100)\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute predictions for each movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ratings_matrix: The ratings matrix with dimension movies x users\n",
    "### movie: Index of movie we want to predict (from 0 to 9999)\n",
    "### similarity_matrix: The similarity matrix between al users\n",
    "### users_to_predict: The list of users (indices) for which we want to compute the predictions\n",
    "### K_best: The number of neighbors to keep for each prediction \n",
    "def compute_predictions_movie(ratings_matrix, movie, similarity_matrix, users_to_predict, K_best):\n",
    "    \"\"\"Compute all the wanted predictions for the given movie and returns the predictions in an array\"\"\"\n",
    "    ratings = ratings_matrix[movie]\n",
    "    # Following steps: only keep the similarities (user) if they have seen the movie\n",
    "    copiedRatings = np.tile(ratings, (len(users_to_predict), 1))\n",
    "    copiedRatings[copiedRatings != 0] = 1\n",
    "    # Get similarity matrix of the wanted users with dimension: all users (10000) x wanted users(< 10000)\n",
    "    similarities = similarity_matrix[users_to_predict].T\n",
    "    similarities = np.multiply(similarities, copiedRatings.T)\n",
    "    \n",
    "    # Apply function getTopKNeighbors to each column of similarities to keep K best similarities for each user\n",
    "    bestNeighbors = np.apply_along_axis(getTopKNeighbors, 0, similarities, K_best)\n",
    "    # Get a list of sums of each column of bestNeighbors\n",
    "    sumSimilarities = np.sum(bestNeighbors, axis = 0)\n",
    "\n",
    "    #Compute prediction: dot product of the items in ratings @ bestNeighbors divided by the corresponding sum of similarities\n",
    "    predictions = np.dot(ratings, bestNeighbors)\n",
    "    predictions = predictions / sumSimilarities\n",
    "    predictions[np.isnan(predictions)] = 0.0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_matrix_predictions(ratings_matrix, ratings_to_predict, similarity_matrix, K_best):\n",
    "    \"\"\"Compute the wanted predictions by running the compute_predictions_movie for each movie\"\"\"\n",
    "    nb_users = len(ratings_matrix)\n",
    "    nb_movies = len(ratings_matrix[0])\n",
    "    movie_user_matrix = ratings_matrix.T \n",
    "    predictions = []\n",
    "    ### Compute wanted predictions for wanted users\n",
    "    for movie in range(nb_movies):\n",
    "        if(movie % 100 == 0):\n",
    "            print(\"Percentage: {}\".format(100*movie/nb_movies))\n",
    "        users_to_predict = ratings_to_predict[movie]\n",
    "        predictions_movie = compute_predictions_movie(movie_user_matrix, movie, similarity_matrix, users_to_predict, K_best)\n",
    "        predictions.append(predictions_movie)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "predictions_matrix = compute_matrix_predictions(ratings_matrix, ratings_to_predict, cosine_matrix, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_ids_for_submission(ids):\n",
    "    result = []\n",
    "    for id_ in ids:\n",
    "        newId = 'r'+str(id_[0])+'_c'+str(id_[1])\n",
    "        result.append(newId)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv_submission(ids, pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (ids of user,movies we want to predict)\n",
    "               pred (predicted ratings)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames, lineterminator = '\\n')\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, pred):\n",
    "            writer.writerow({'Id':str(r1),'Prediction':float(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_sub = convert_ids_for_submission(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176952 1176952\n"
     ]
    }
   ],
   "source": [
    "### Flatten the matrix row by row into a list of predictions\n",
    "preds = [p for movie_preds in predictions_matrix for p in movie_preds]\n",
    "### Create csv submission\n",
    "print(len(ids_sub), len(preds))\n",
    "create_csv_submission(ids_sub, preds, \"user-userCF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
